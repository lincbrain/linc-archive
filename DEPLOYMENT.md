## EC2 instance
Currently we are using an ec2 instance with the following specification:
- Instance type: t3.medium
- Region: US East (Ohio)
- IAM role: write-public-dataset
- AMI: ubuntu-bionic-18.04
- Volume: 100GB
- Security Group Outbound: Make sure DNS (UDP) on port 53 is available for all destinations (meaning “anywhere” is selected)
## S3 Bucket Access From a Different Account
Currently the s3 bucket which is used as girder’s assetstore lives in a different AWS account. In order to overcome the access issues, we had to follow [these instructions](https://aws.amazon.com/premiumsupport/knowledge-center/s3-instance-access-bucket/). The IAM role mentioned in the previous section (write-public-dataset) was generated by following the guide.
The following config file is added to the instance by ansible to ~/.aws/config path to enable cross account access. As we are accessing this S3 bucket via an IAM role, we are not saving credentials into the Girder Assetstore object and are instead setting the `infer credentials` flag on the Assetstore.

```ini
[default]
region = us-east-2
role_arn = arn:aws:iam::769362853226:role/dandi-writer
credential_source = Ec2InstanceMetadata
```

## Ansible

We have an ansible playbook that gets run against the EC2 instance upon a merge to master. The playbook installs and configures mongodb, nginx and girder as roles as well as a girder plugin that is tailored for this project. Details about these roles can be found:
- [ansible-role-girder-mongodb](https://github.com/girder/ansible-role-girder-mongodb)
- [ansible-role-girder](https://github.com/girder/ansible-role-girder)
- [ansible-role-girder-nginx](https://github.com/girder/ansible-role-girder-nginx)

We also install the following plugins for girder from pypi:
- girder-oauth
- girder-sentry
- girder-hashsum-download
- girder-download-statistics

and the custom [girder-dandi-archive](https://github.com/dandi/dandiarchive/tree/master/girder-dandi-archive) plugin from github. Each time CI is triggered, the ansible playbook will install the latest version of that plugin from github. 
The Ansible playbook will be the reliable way to recreate dandiarchive deployment. If there is discrepancies between this document and ansible playbook, take the ansible playbook as the source of truth. 

## Continuous Integration

CirclCI is used for continuously provisioning the production instance. Whenever there is a merge to the master branch of dandiarchive CircleCI runs the playbook against the production instance. We are using a very simple CircleCI configuration file. This way the playbook gets exercised frequently and consequently lowers the maintenance cost.

Only tricky part is adding the private AWS key so that the CI machine can provision the EC2 instance. [Environment variables](https://circleci.com/docs/2.0/env-vars/) in CircleCI is used for that purpose. We are injecting the private key via an environment variable called "ANSIBLE_PRIVATE_KEY_FILE". When that environment variable is declared, ansible will pick it up automatically.

## Client Builds

For building and serving the custom vue client for dandiarchive, we are using Netlify. Netlify uses git hooks and will trigger a client build and deployment whenever there is a PR submit or a merge to master. Upon PR submissions Netlify provides a preview url but due to some CORS complications (Girder not supporting subdomain wildcards) we cannot enable CORS access to preview urls without insecure practices. With a merge to master it will build and deploy the client to https://gui.dandiarchive.org/.

## Oauth

Besides girder's own authentication system, dandiarchive provides a Github based authentication using girder-oauth plugin.

## DNS

We are using Google's [public DNS service](https://developers.google.com/speed/public-dns).

## E-mail

We are using [mailgun](https://www.mailgun.com/) as our e-mail service. This is email that comes from Girder, which is mostly used for resetting passwords, and as most users will be logging in via OAuth, this will largely be unused.
